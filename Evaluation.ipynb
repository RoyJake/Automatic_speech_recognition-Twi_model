{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_D-bmnPLxZOv","executionInfo":{"status":"ok","timestamp":1738070760833,"user_tz":0,"elapsed":23464,"user":{"displayName":"R O","userId":"09673851489656693083"}},"outputId":"b921d4fb-fb5e-43d7-e419-80fc3a26f7f6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ng_JtYqBk76A"},"outputs":[],"source":["%%capture\n","!pip install --upgrade datasets\n","!pip install torchaudio\n","!pip install librosa\n","!pip install jiwer\n","!pip install --upgrade evaluate datasets\n","!pip install --upgrade transformers huggingface_hub\n","!pip install pydub"]},{"cell_type":"markdown","source":["**PREPROCESSING NEW DATA FOR MODEL EVALUATION**"],"metadata":{"id":"kuoIh6Z-KnRg"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"rQkfmwpsb1Vi"},"outputs":[],"source":["import pandas as pd\n","\n","eval_test_df = pd.read_csv('/content/drive/MyDrive/Twi_ASR/evaluation/eval_dataset.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yQTwf8VOfdnd"},"outputs":[],"source":["from datasets import Dataset\n","\n","# Converting pandas DataFrame to Hugging Face Dataset\n","eval_test = Dataset.from_pandas(eval_test_df)"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"LMcWkQ1rcmtW"},"outputs":[],"source":["\"\"\"from pydub import AudioSegment\n","\n","# Load video file\n","video_file = \"/content/drive/MyDrive/evaluation/eval_audio/eval_audio_2.flac\"\n","audio = AudioSegment.from_file(video_file, format=\"flac\")  # Adjust format if necessary\n","\n","# Export as MP3\n","audio.export(\"/content/drive/MyDrive/evaluation/eval_audio/eval_audio_2.wav\", format=\"wav\")\n","\n","print(\"Audio extracted successfully!\")\"\"\"\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BbIiIYGGeaM_"},"outputs":[],"source":["import torchaudio\n","import os\n","\n","# Define base path to the raw_audio folder\n","base_path = \"/content/drive/MyDrive/evaluation/eval_audio\"\n","\n","def speech_file_to_array_fn(batch):\n","\n","    speech_array, sampling_rate = torchaudio.load(os.path.join(base_path, batch[\"audio\"]))\n","    batch[\"speech\"] = speech_array[0].numpy()\n","    batch[\"sampling_rate\"] = sampling_rate\n","    batch[\"target_text\"] = batch[\"sentence\"]\n","\n","    return batch"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["2dd17056e90545d2942ebe3b74f5431f"]},"executionInfo":{"elapsed":1328,"status":"ok","timestamp":1737848420303,"user":{"displayName":"Bible_data","userId":"00248855130909158686"},"user_tz":0},"id":"sD3bWjlgeaNA","outputId":"ce36516c-e107-43ea-c9ba-17a93b34b324"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2dd17056e90545d2942ebe3b74f5431f","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/2 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["eval_test = eval_test.map(speech_file_to_array_fn, remove_columns=eval_test.column_names, num_proc=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"603lpOWpeaND"},"outputs":[],"source":["import librosa\n","import numpy as np\n","\n","def resample_audio(batch):\n","    \"\"\"\n","    Resample audio data in 'speech' to 16kHz.\n","    \"\"\"\n","    # Ensure 'speech' and 'sampling_rate' exist in batch\n","    if \"speech\" in batch and \"sampling_rate\" in batch:\n","        audio = np.asarray(batch[\"speech\"])  # Convert speech to NumPy array\n","        orig_sr = batch[\"sampling_rate\"]     # Original sampling rate\n","\n","        # Perform resampling\n","        batch[\"speech\"] = librosa.resample(y=audio, orig_sr=orig_sr, target_sr=16000)\n","        batch[\"sampling_rate\"] = 16000  # Update sampling rate\n","\n","    return batch"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["e4aa18326e0d4df2b4199f0d6444451f"]},"executionInfo":{"elapsed":11074,"status":"ok","timestamp":1737848432904,"user":{"displayName":"Bible_data","userId":"00248855130909158686"},"user_tz":0},"id":"F-qECxHDeaND","outputId":"4dbe12c2-c3ff-42c5-e963-f3d61d5ac046"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e4aa18326e0d4df2b4199f0d6444451f","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/2 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["eval_test = eval_test.map(resample_audio, num_proc=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2A0-Led9gGkO"},"outputs":[],"source":["def prepare_dataset(batch):\n","    # check that all files have the correct sampling rate\n","    assert (\n","        len(set(batch[\"sampling_rate\"])) == 1\n","    ), f\"Make sure all inputs have the same sampling rate of {processor.feature_extractor.sampling_rate}.\"\n","\n","    batch[\"input_values\"] = processor(batch[\"speech\"], sampling_rate=batch[\"sampling_rate\"][0]).input_values\n","\n","    with processor.as_target_processor():\n","        batch[\"labels\"] = processor(batch[\"target_text\"]).input_ids\n","    return batch"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":104,"referenced_widgets":["1ae433b25e2445dcbff97c0b0bfc6a11"]},"executionInfo":{"elapsed":1474,"status":"ok","timestamp":1737848489493,"user":{"displayName":"Bible_data","userId":"00248855130909158686"},"user_tz":0},"id":"weasN5FIgGkP","outputId":"940b42ef-5667-47d0-88b0-c9997143ddf5"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1ae433b25e2445dcbff97c0b0bfc6a11","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/2 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n","  warnings.warn(\n"]}],"source":["eval_test = eval_test.map(prepare_dataset, remove_columns=eval_test.column_names, batch_size=8, num_proc=1, batched=True)"]},{"cell_type":"markdown","source":["**ALREADY PROCESSED DATA FOR MODEL EVALUATION**"],"metadata":{"id":"zI5r52KJK_cn"}},{"cell_type":"code","source":["from datasets import load_from_disk\n","\n","eval_test = load_from_disk(\"/content/drive/MyDrive/Twi_ASR/PD_21237:33102_2688:4033/train_dataset\")"],"metadata":{"id":"duL-Ot3EFBja"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","\n","reference = pd.read_csv('/content/drive/MyDrive/Twi_ASR/train.csv')\n","reference = reference.iloc[21237:33102]"],"metadata":{"id":"X_9vWGUOHgiW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from datasets import Dataset\n","\n","# Converting pandas DataFrame to Hugging Face Dataset\n","reference = Dataset.from_pandas(reference)"],"metadata":{"id":"wLbbh3uqJNEk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**SETUP FOR MODEL EVALUATION**"],"metadata":{"id":"f2NQPI5TLPpZ"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"CchRfemUtga4"},"outputs":[],"source":["from transformers import Wav2Vec2CTCTokenizer\n","\n","tokenizer = Wav2Vec2CTCTokenizer(\"/content/drive/MyDrive/Twi_ASR/vocab.json\", unk_token=\"[UNK]\", pad_token=\"[PAD]\", word_delimiter_token=\"|\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y6ZHj8t7tga6"},"outputs":[],"source":["from transformers import Wav2Vec2FeatureExtractor\n","\n","feature_extractor = Wav2Vec2FeatureExtractor(feature_size=1, sampling_rate=16000, padding_value=0.0, do_normalize=True, return_attention_mask=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F3cqK7Ivtga7"},"outputs":[],"source":["from transformers import Wav2Vec2Processor\n","\n","processor = Wav2Vec2Processor(feature_extractor=feature_extractor, tokenizer=tokenizer)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"otIsKbcviBwr"},"outputs":[],"source":["from transformers import Wav2Vec2ForCTC\n","\n","model = Wav2Vec2ForCTC.from_pretrained(\"/content/drive/MyDrive/Twi_ASR/wav2vec2-large-xlsr-twi_PD/checkpoint-22260\").to(\"cuda\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8eL4ThCukHXs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1738072563179,"user_tz":0,"elapsed":370,"user":{"displayName":"R O","userId":"09673851489656693083"}},"outputId":"ed68ca0b-796f-4e43-bc75-81a9f71e0030"},"outputs":[{"output_type":"stream","name":"stderr","text":["It is strongly recommended to pass the ``sampling_rate`` argument to this function. Failing to do so can result in silent errors that might be hard to debug.\n"]}],"source":["import torch\n","\n","input_dict = processor(eval_test[900][\"input_values\"], return_tensors=\"pt\", padding=True)\n","logits = model(input_dict.input_values.to(\"cuda\")).logits\n","pred_ids = torch.argmax(logits, dim=-1)[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gnUj1Zoy_g_M"},"outputs":[],"source":["print(\"Prediction:\")\n","print(processor.decode(pred_ids))\n","\n","print(\"\\nReference:\")\n","print(reference[900][\"sentence\"].lower())"]},{"cell_type":"code","source":[],"metadata":{"id":"007tNlZhH07c"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"authorship_tag":"ABX9TyNSsPgwnvE7aTGqxHMyaHQg"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}